# -*- coding: utf-8 -*-
"""treinar_modelo_attrition.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-3wAYqa2WVV0p7OlnveLa1HRx-wz_Sy2
"""

import pandas as pd
import pickle
import joblib
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (
    classification_report,
    confusion_matrix,
    accuracy_score,
    precision_recall_curve
)
from datetime import datetime

# 1. CARREGAMENTO E ENGENHARIA DE ATRIBUTOS
# =======================================
# Carregar o novo dataset com as datas
df_dates = pd.read_csv('/content/drive/MyDrive/Projetos/RH_with_dates.csv', sep=';')

# Converter colunas de data para o formato datetime
df_dates['admission_date'] = pd.to_datetime(df_dates['admission_date'], errors='coerce')
df_dates['resignation_date'] = pd.to_datetime(df_dates['resignation_date'], errors='coerce')

# Determinar a data de referência ("hoje") como a data mais recente no dataset
latest_admission = df_dates['admission_date'].max()
latest_resignation = df_dates['resignation_date'].max()
today_reference = max(latest_admission, latest_resignation)

# Calcular o tempo de casa (tenure) em dias
df_dates['tenure_in_days'] = (
    df_dates['resignation_date'].fillna(today_reference) - df_dates['admission_date']
).dt.days

# Limpar dados inválidos que possam ter sido gerados
df_dates.dropna(subset=['tenure_in_days'], inplace=True)
df_dates = df_dates[df_dates['tenure_in_days'] >= 0]


# 2. PREPARAÇÃO DOS DADOS PARA O MODELO
# =======================================
# Remover colunas originais de datas e outras desnecessárias
df_model = df_dates.drop([
    'admission_date', 'resignation_date', 'EmployeeCount',
    'EmployeeNumber', 'Over18', 'StandardHours'
], axis=1)

# Converter a variável alvo 'Attrition' para formato numérico (0 ou 1)
df_model['Attrition'] = df_model['Attrition'].apply(lambda x: 1 if x == 'Yes' else 0)

# Separar os dados em features (X) e variável alvo (y)
X = df_model.drop('Attrition', axis=1)
y = df_model['Attrition']

# 3. PRÉ-PROCESSAMENTO E TREINAMENTO
# =======================================
# Identificar colunas numéricas (incluindo a nova 'tenure_in_days') e categóricas
categorical_features = X.select_dtypes(include=['object']).columns
numerical_features = X.select_dtypes(include=np.number).columns

# Criar os transformadores
numerical_transformer = StandardScaler()
categorical_transformer = OneHotEncoder(handle_unknown='ignore')

# Combinar os transformadores em um pipeline de pré-processamento
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numerical_transformer, numerical_features),
        ('cat', categorical_transformer, categorical_features)
    ])

# Dividir os dados em conjuntos de treinamento e teste
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Criar e treinar o pipeline completo com o classificador RandomForest
rf_pipeline_new = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', RandomForestClassifier(
        random_state=42,
        class_weight='balanced',
        n_estimators=100
    ))
])

print("Treinando o novo modelo com a feature 'tenure_in_days'...")
rf_pipeline_new.fit(X_train, y_train)
print("Treinamento concluído.")

# 4. AJUSTE DO LIMIAR E AVALIAÇÃO
# =======================================
# Prever as probabilidades para a classe positiva
y_scores_new = rf_pipeline_new.predict_proba(X_test)[:, 1]

# Calcular precisão, recall e limiares para encontrar o ponto ótimo
precision_new, recall_new, thresholds_new = precision_recall_curve(y_test, y_scores_new)

# Encontrar o melhor limiar com base no F1-score
f1_scores_new = np.nan_to_num(2 * (precision_new * recall_new) / (precision_new + recall_new))
best_threshold_index_new = np.argmax(f1_scores_new)
best_threshold_new = thresholds_new[best_threshold_index_new]

print(f"\nMelhor limiar de decisão encontrado: {best_threshold_new:.4f}")

# Aplicar o novo limiar para gerar as previsões finais
y_pred_adjusted_new = (y_scores_new >= best_threshold_new).astype(int)

# 5. RESULTADOS DO MODELO ATUALIZADO
# =======================================
print("\n--- Resultados Finais do Modelo Atualizado (com 'tenure_in_days') ---")
accuracy_new = accuracy_score(y_test, y_pred_adjusted_new)
conf_matrix_new = confusion_matrix(y_test, y_pred_adjusted_new)
class_report_new = classification_report(y_test, y_pred_adjusted_new)

print(f"Acurácia do modelo: {accuracy_new:.2f}")
print("\nMatriz de Confusão:")
print(conf_matrix_new)
print("\nRelatório de Classificação:")
print(class_report_new)


# 6. ANÁLISE VISUAL DOS RESULTADOS
# =======================================
print("\nGerando gráficos para análise visual...")

# Gráfico 1: Curva Precision-Recall
plt.figure(figsize=(10, 7))
plt.plot(recall_new, precision_new, marker='.', label='Random Forest')
plt.scatter(
    recall_new[best_threshold_index_new],
    precision_new[best_threshold_index_new],
    marker='o',
    color='red',
    label=f'Melhor Limiar ({best_threshold_new:.2f})',
    s=100,
    zorder=5
)
plt.title('Curva Precision-Recall', fontsize=16)
plt.xlabel('Recall (Revocação)', fontsize=12)
plt.ylabel('Precision (Precisão)', fontsize=12)
plt.legend()
plt.grid(True)
plt.show()


# Gráfico 2: Matriz de Confusão Visual (Heatmap)
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix_new, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Não Saiu', 'Saiu'], yticklabels=['Não Saiu', 'Saiu'])
plt.xlabel('Previsão do Modelo', fontsize=12)
plt.ylabel('Valor Real', fontsize=12)
plt.title('Matriz de Confusão', fontsize=16)
plt.show()


# Gráfico 3: Importância dos Atributos
# Obter os nomes de todas as features após o pré-processamento
ohe_feature_names = rf_pipeline_new.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names_out(categorical_features)
all_feature_names = np.concatenate([numerical_features, ohe_feature_names])

# Obter as importâncias do modelo treinado
importances = rf_pipeline_new.named_steps['classifier'].feature_importances_

# Criar um DataFrame e exibir as features mais importantes
feature_importance_df = pd.DataFrame({'Feature': all_feature_names, 'Importance': importances})
feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False).head(15)

plt.figure(figsize=(12, 8))
sns.barplot(x='Importance', y='Feature', data=feature_importance_df, palette='viridis')
plt.title('Top 15 Atributos Mais Importantes', fontsize=16)
plt.xlabel('Importância', fontsize=12)
plt.ylabel('Atributo', fontsize=12)
plt.tight_layout()
plt.show()

print("\nSalvando o pipeline treinado...")
joblib.dump(rf_pipeline_new, 'modelo_attrition_pipeline.joblib')
print("Pipeline salvo com sucesso em 'modelo_attrition_pipeline.joblib'")

print("\nSalvando o pipeline treinado com pickle...")
with open('modelo_attrition_pipeline.pkl', 'wb') as file:
    pickle.dump(rf_pipeline_new, file)
print("Pipeline salvo com sucesso em 'modelo_attrition_pipeline.pkl'")

from sklearn.metrics import roc_curve, auc

# Gráfico 4: Curva ROC
print("\nGerando gráfico da Curva ROC...")

fpr_new, tpr_new, _ = roc_curve(y_test, y_scores_new)
roc_auc_new = auc(fpr_new, tpr_new)

plt.figure(figsize=(10, 7))
plt.plot(fpr_new, tpr_new, color='darkorange', lw=2, label=f'Curva ROC (AUC = {roc_auc_new:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Taxa de Falso Positivo')
plt.ylabel('Taxa de Verdadeiro Positivo')
plt.title('Curva Característica de Operação do Receptor (ROC)', fontsize=16)
plt.legend(loc="lower right")
plt.grid(True)
plt.show()

# Gráfico 5: Distribuição de 'tenure_in_days' por Attrition
print("\nGerando gráfico da distribuição de 'tenure_in_days'...")

plt.figure(figsize=(10, 7))
sns.histplot(data=df_dates, x='tenure_in_days', hue='Attrition', kde=True, palette='viridis', bins=50)
plt.title('Distribuição de Tempo de Casa (dias) por Rotatividade', fontsize=16)
plt.xlabel('Tempo de Casa (dias)', fontsize=12)
plt.ylabel('Contagem', fontsize=12)
plt.grid(True)
plt.show()

# Gráfico 6: Distribuição de Attrition por Departamento
print("\nGerando gráfico da distribuição de Attrition por Departamento...")

plt.figure(figsize=(10, 7))
sns.countplot(data=df_model, x='Department', hue='Attrition', palette='viridis')
plt.title('Distribuição de Rotatividade por Departamento', fontsize=16)
plt.xlabel('Departamento', fontsize=12)
plt.ylabel('Contagem', fontsize=12)
plt.grid(axis='y')
plt.show()

# Gráfico 7: Distribuição de Attrition por Job Role
print("\nGerando gráfico da distribuição de Attrition por Cargo...")

plt.figure(figsize=(14, 7))
sns.countplot(data=df_model, y='JobRole', hue='Attrition', palette='viridis')
plt.title('Distribuição de Rotatividade por Cargo', fontsize=16)
plt.xlabel('Contagem', fontsize=12)
plt.ylabel('Cargo', fontsize=12)
plt.grid(axis='x')
plt.tight_layout()
plt.show()